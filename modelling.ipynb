{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(1, 3), dtype=int32, numpy=array([[1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones([1, 3], tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEmbeddings(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_buckets=None, embedding_size=None,*args, **kwargs):\n",
    "        super(GetEmbeddings, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding = tf.constant([[1.0,1.0,1.0,1.0],[2.0,2.0,2.0,2.0],[3.0,3.0,3.0,3.0],[4.0,4.0,4.0,4.0]]) # Embedding matrix\n",
    "    \n",
    "    def call(self, input):\n",
    "        user = input[0]\n",
    "        movie = input[1]\n",
    "        # Expand user to get it to a matrix of 1 and zeros instead\n",
    "        user = tf.expand_dims(user, 2)\n",
    "        user = tf.tile(user, [1,1, 4])\n",
    "        # check equality of array in t1 for each array in t2 element by element. This is possible because the equal function supports broadcasting. \n",
    "        equal =  tf.math.equal(tf.constant([1.0,1.0,1.0,1.0]), user)\n",
    "        # checking if all elements from  t1 match for all elements of some array in t2\n",
    "        equal_all = tf.reduce_all(equal, axis=2)\n",
    "        user_embeddings = self.embedding * user \n",
    "        # Get embeddings for the users based upon the movies he/she watched\n",
    "        # Expand the movie first\n",
    "        movies = tf.expand_dims(movie,2)\n",
    "        movies = tf.tile(movies, [1,1, 4])\n",
    "        # Get the embeddings\n",
    "        movie_embeddings = self.embedding * movies\n",
    "        # Only want the movies with values\n",
    "        equal_movie =  tf.math.not_equal(tf.constant([0.0,0.0,0.0,0.0]), movie_embeddings)\n",
    "        equal_all_movie = tf.reduce_all(equal, axis=1)\n",
    "        # Get the indicies where we have a movie\n",
    "        indices = tf.where(equal_movie)\n",
    "        # In order to to the pointwise multiplication I need to have the same shape so expand\n",
    "        out = tf.reshape(tf.gather_nd(movie_embeddings,indices),shape=(2,1,4))\n",
    "        out = tf.tile(out,multiples=[1,4,1])\n",
    "        # Point wise multiplication, each movie the user watched multiplied with this movie\n",
    "        output = tf.math.multiply(out,user_embeddings)\n",
    "        lenght =  tf.reduce_sum(tf.cast(equal_all, tf.float32),axis=1)\n",
    "        mean = tf.reduce_sum(tf.cast(output,dtype=tf.float32),axis=1) / tf.reshape(lenght, (-1, 1))\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEmbeddings(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_buckets=None, embedding_size=None,*args, **kwargs):\n",
    "        super(GetEmbeddings, self).__init__(*args, **kwargs)\n",
    "        self.movies = num_buckets\n",
    "        self.embedding_size = embedding_size\n",
    "        #self.shape = compute_output_shape\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "        self.embedding = tf.constant([[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]]) # Embedding matrix\n",
    "        self.kernel = self.add_variable(\"kernel\",\n",
    "                                    shape=[self.movies,\n",
    "                                           self.embedding_size],dtype=tf.float32,initializer=tf.keras.initializers.RandomUniform(),trainable=True)\n",
    "        \n",
    "    def call(self, input):\n",
    "        #input = tf.reshape(input)\n",
    "        #movies_new = concated[:,:4]\n",
    "        #users_new = concated[:,4:]\n",
    "        user = input[:,:self.movies]\n",
    "        movie = input[:,self.movies:]\n",
    "        # Expand user to get it to a matrix of 1 and zeros instead\n",
    "        user = tf.expand_dims(user, 2)\n",
    "        user = tf.tile(user, [1,1, self.embedding_size])\n",
    "        # check equality of array in t1 for each array in t2 element by element. This is possible because the equal function supports broadcasting. \n",
    "        #equal =  tf.math.equal(tf.constant([1,1,1,1]), user)       \n",
    "        equal =  tf.math.equal(tf.ones([1, self.embedding_size]), user)\n",
    "        # checking if all elements from  t1 match for all elements of some array in t2\n",
    "        equal_all = tf.reduce_all(equal, axis=2)      \n",
    "        #user_embeddings = self.embedding * user \n",
    "        user_embeddings = self.kernel * user\n",
    "        # Get embeddings for the users based upon the movies he/she watched\n",
    "        # Expand the movie first\n",
    "        movies = tf.expand_dims(movie,2)\n",
    "        movies = tf.tile(movies, [1,1, self.embedding_size])\n",
    "        # Get the embeddings\n",
    "        #movie_embeddings = self.embedding * movies      \n",
    "        movie_embeddings = self.kernel * movies        \n",
    "        # Only want the movies with values \n",
    "        equal_movie =  tf.math.not_equal(tf.zeros([1, self.embedding_size]), movie_embeddings)\n",
    "        #print(equal_movie)\n",
    "        equal_all_movie = tf.reduce_all(equal, axis=1)\n",
    "        #print(equal_all_movie)\n",
    "        # Get the indicies where we have a movie\n",
    "        indices = tf.where(equal_movie)\n",
    "        # In order to to the pointwise multiplication I need to have the same shape so expand\n",
    "        #print(tf.gather_nd(movie_embeddings,indices))\n",
    "        out = tf.reshape(tf.gather_nd(movie_embeddings,indices),shape=(tf.shape(user)[0],1,self.embedding_size))\n",
    "        out = tf.tile(out,multiples=[1,self.movies,1])\n",
    "        #print(tf.math.multiply(out[1],user_embeddings))\n",
    "        # Point wise multiplication, each movie the user watched multiplied with this movie\n",
    "        output = tf.math.multiply(user_embeddings,out)\n",
    "        #print(output)\n",
    "        #print(tf.shape(output))\n",
    "        #output = tf.reshape(output,shape=(self.batch_size,self.movies,self.embedding_size))\n",
    "        mean = tf.reduce_sum(tf.cast(output,dtype=tf.float32),axis=1) / self.movies\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=75, shape=(4, 10), dtype=float32, numpy=\n",
       "array([[ 1.13413483e-03,  5.88357070e-05,  1.05595325e-04,\n",
       "         2.26339384e-04, -1.56531125e-04, -6.48036876e-05,\n",
       "        -1.94309861e-04, -1.63331410e-04, -3.64638167e-04,\n",
       "        -9.99023905e-06],\n",
       "       [ 4.24248428e-04,  2.68042670e-04, -2.01234405e-04,\n",
       "         1.02813421e-04, -6.06444883e-05,  9.91362976e-05,\n",
       "        -1.80924799e-05, -5.02739385e-05, -1.45078564e-04,\n",
       "         3.37964084e-05],\n",
       "       [ 4.22851561e-04, -1.67394246e-04,  1.40525080e-04,\n",
       "         2.05030810e-04, -3.40822567e-07, -8.94158075e-05,\n",
       "        -2.33745464e-04, -5.64438014e-05, -7.81728595e-05,\n",
       "        -1.97265967e-06],\n",
       "       [ 4.22851561e-04, -1.67394246e-04,  1.40525080e-04,\n",
       "         2.05030810e-04, -3.40822567e-07, -8.94158075e-05,\n",
       "        -2.33745464e-04, -5.64438014e-05, -7.81728595e-05,\n",
       "        -1.97265967e-06]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = GetEmbeddings(4,10)\n",
    "user = tf.constant([[1.0,1.0,1.0,1.0],[1.0,0.0,0.0,0.0],[1.0,0.0,0.0,0.0],[1.0,0.0,0.0,0.0]]) # Example user, two users\n",
    "#PROBLEMS PROBLEMS \n",
    "movie = tf.constant([[1.0,0.0,0.0,0.0],[0.0,1.0,0.0,0.0],[0.0,0.0,1.0,0.0],[0.0,0.0,1.0,0.0]]) \n",
    "concated = tf.concat([tf.cast(user,dtype=tf.int32),tf.cast(movie,tf.int32)],axis=1)\n",
    "concated = tf.cast(concated,tf.float32)\n",
    "layer(concated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=11, shape=(4, 8), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer with dense layer connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(8,)) # Don't forget the comma\n",
    "x  = GetEmbeddings(4,10)(inputs)\n",
    "x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "get_embeddings_1 (GetEmbeddi (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 425\n",
      "Trainable params: 425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              # List of metrics to monitor\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = concated\n",
    "y_train = tf.constant([0,0,0,0])\n",
    "x_val=x_train\n",
    "y_val=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 4 samples\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2900 - binary_accuracy: 1.0000 - val_loss: 0.2805 - val_binary_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2805 - binary_accuracy: 1.0000 - val_loss: 0.2735 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2735 - binary_accuracy: 1.0000 - val_loss: 0.2676 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2676 - binary_accuracy: 1.0000 - val_loss: 0.2623 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2623 - binary_accuracy: 1.0000 - val_loss: 0.2575 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 853us/sample - loss: 0.2575 - binary_accuracy: 1.0000 - val_loss: 0.2529 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2529 - binary_accuracy: 1.0000 - val_loss: 0.2487 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2487 - binary_accuracy: 1.0000 - val_loss: 0.2447 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2447 - binary_accuracy: 1.0000 - val_loss: 0.2408 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2408 - binary_accuracy: 1.0000 - val_loss: 0.2371 - val_binary_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2371 - binary_accuracy: 1.0000 - val_loss: 0.2335 - val_binary_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2335 - binary_accuracy: 1.0000 - val_loss: 0.2300 - val_binary_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 942us/sample - loss: 0.2300 - binary_accuracy: 1.0000 - val_loss: 0.2265 - val_binary_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2265 - binary_accuracy: 1.0000 - val_loss: 0.2232 - val_binary_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 850us/sample - loss: 0.2232 - binary_accuracy: 1.0000 - val_loss: 0.2200 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2200 - binary_accuracy: 1.0000 - val_loss: 0.2168 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2168 - binary_accuracy: 1.0000 - val_loss: 0.2137 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 907us/sample - loss: 0.2137 - binary_accuracy: 1.0000 - val_loss: 0.2106 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2106 - binary_accuracy: 1.0000 - val_loss: 0.2076 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 937us/sample - loss: 0.2076 - binary_accuracy: 1.0000 - val_loss: 0.2046 - val_binary_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2046 - binary_accuracy: 1.0000 - val_loss: 0.2017 - val_binary_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2017 - binary_accuracy: 1.0000 - val_loss: 0.1989 - val_binary_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1989 - binary_accuracy: 1.0000 - val_loss: 0.1960 - val_binary_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1960 - binary_accuracy: 1.0000 - val_loss: 0.1933 - val_binary_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1933 - binary_accuracy: 1.0000 - val_loss: 0.1905 - val_binary_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1905 - binary_accuracy: 1.0000 - val_loss: 0.1878 - val_binary_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1878 - binary_accuracy: 1.0000 - val_loss: 0.1851 - val_binary_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1851 - binary_accuracy: 1.0000 - val_loss: 0.1825 - val_binary_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1825 - binary_accuracy: 1.0000 - val_loss: 0.1799 - val_binary_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1799 - binary_accuracy: 1.0000 - val_loss: 0.1773 - val_binary_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1773 - binary_accuracy: 1.0000 - val_loss: 0.1748 - val_binary_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1748 - binary_accuracy: 1.0000 - val_loss: 0.1722 - val_binary_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1722 - binary_accuracy: 1.0000 - val_loss: 0.1698 - val_binary_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1698 - binary_accuracy: 1.0000 - val_loss: 0.1673 - val_binary_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1673 - binary_accuracy: 1.0000 - val_loss: 0.1649 - val_binary_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1649 - binary_accuracy: 1.0000 - val_loss: 0.1625 - val_binary_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1625 - binary_accuracy: 1.0000 - val_loss: 0.1601 - val_binary_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1601 - binary_accuracy: 1.0000 - val_loss: 0.1578 - val_binary_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1578 - binary_accuracy: 1.0000 - val_loss: 0.1555 - val_binary_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1555 - binary_accuracy: 1.0000 - val_loss: 0.1532 - val_binary_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1532 - binary_accuracy: 1.0000 - val_loss: 0.1509 - val_binary_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1509 - binary_accuracy: 1.0000 - val_loss: 0.1487 - val_binary_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1487 - binary_accuracy: 1.0000 - val_loss: 0.1465 - val_binary_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1465 - binary_accuracy: 1.0000 - val_loss: 0.1443 - val_binary_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1443 - binary_accuracy: 1.0000 - val_loss: 0.1421 - val_binary_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1421 - binary_accuracy: 1.0000 - val_loss: 0.1400 - val_binary_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1400 - binary_accuracy: 1.0000 - val_loss: 0.1379 - val_binary_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1379 - binary_accuracy: 1.0000 - val_loss: 0.1358 - val_binary_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1358 - binary_accuracy: 1.0000 - val_loss: 0.1337 - val_binary_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1337 - binary_accuracy: 1.0000 - val_loss: 0.1317 - val_binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=50,\n",
    "                    # We pass some validation for\n",
    "                    # monitoring validation loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data form csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df = pd.read_csv(\"data/1000test_Heynicklas.csv\")\n",
    "\n",
    "def flatten(input):\n",
    "    \"\"\"\"\"\"\n",
    "    list_one = input[0]\n",
    "    list_two = input[1]\n",
    "    output = list_one + list_two\n",
    "    return output\n",
    "\n",
    "def list_converter(input):\n",
    "    output = ast.literal_eval(input)\n",
    "    output = [float(value) for value in output]\n",
    "    return output\n",
    "\n",
    "df['userID'] = df['userID'].apply(list_converter)\n",
    "df['movieID'] = df['movieID'].apply(list_converter)\n",
    "\n",
    "\n",
    "df['input']=df['userID']+df['movieID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(df[\"userID\"].values)[0])\n",
    "# 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('ratings')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df_to_dataset(df[[\"input\",\"ratings\"]], shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model with the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[[\"input\",\"ratings\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = test_df.pop('ratings')\n",
    "dict_slices = tf.data.Dataset.from_tensor_slices((test_df.to_dict('list'), target.values)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input': <tf.Tensor: id=9467, shape=(1, 2000), dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}, <tf.Tensor: id=9468, shape=(1,), dtype=int64, numpy=array([1])>)\n",
      "({'input': <tf.Tensor: id=9471, shape=(1, 2000), dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}, <tf.Tensor: id=9472, shape=(1,), dtype=int64, numpy=array([1])>)\n",
      "({'input': <tf.Tensor: id=9475, shape=(1, 2000), dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}, <tf.Tensor: id=9476, shape=(1,), dtype=int64, numpy=array([1])>)\n",
      "({'input': <tf.Tensor: id=9479, shape=(1, 2000), dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}, <tf.Tensor: id=9480, shape=(1,), dtype=int64, numpy=array([1])>)\n",
      "({'input': <tf.Tensor: id=9483, shape=(1, 2000), dtype=float32, numpy=array([[1., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}, <tf.Tensor: id=9484, shape=(1,), dtype=int64, numpy=array([1])>)\n"
     ]
    }
   ],
   "source": [
    "for _ in dict_slices.take(5):\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(2000,),name=\"input\") # Don't forget the comma\n",
    "x  = GetEmbeddings(1000,10)(inputs)\n",
    "x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              # List of metrics to monitor\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 11:59:47.377648 4573812160 training_utils.py:1353] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1055 - binary_accuracy: 0.9990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.4663e-08 - binary_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0000e+00 - binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0000e+00 - binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0000e+00 - binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0000e+00 - binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      " 507/1000 [==============>...............] - ETA: 7s - loss: 0.0000e+00 - binary_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-17123f0da2d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_slices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;31m# Case 3: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1245\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m           \u001b[0mreset_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m           output_loss_metrics=self._output_loss_metrics)\n\u001b[0m\u001b[1;32m   1248\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, reset_metrics, output_loss_metrics)\u001b[0m\n\u001b[1;32m    293\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    296\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         model.optimizer.apply_gradients(zip(grads,\n\u001b[0;32m--> 247\u001b[0;31m                                             model.trainable_weights))\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregated_output_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     return distribute_ctx.get_replica_context().merge_call(\n\u001b[0;32m--> 406\u001b[0;31m         self._distributed_apply, args=(grads_and_vars,), kwargs={\"name\": name})\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   1381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    438\u001b[0m           update_ops.extend(\n\u001b[1;32m    439\u001b[0m               distribution.extended.update(\n\u001b[0;32m--> 440\u001b[0;31m                   var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    441\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mapply_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   1544\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    423\u001b[0m         return self._resource_apply_sparse_duplicate_indices(\n\u001b[1;32m    424\u001b[0m             grad.values, var, grad.indices)\n\u001b[0;32m--> 425\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/rmsprop.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var)\u001b[0m\n\u001b[1;32m    165\u001b[0m             use_locking=self._use_locking)\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m       \u001b[0mrms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m       \u001b[0mrms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrms_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0mdenom_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrms_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_run_op\u001b[0;34m(a, *args, **kwargs)\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_run_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m    889\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mr_binary_op_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1048\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1049\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1050\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/python3.7_beam/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m def _constant_tensor_conversion_function(v, dtype=None, name=None,\n\u001b[0m\u001b[1;32m    302\u001b[0m                                          as_ref=False):\n\u001b[1;32m    303\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(dict_slices,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
