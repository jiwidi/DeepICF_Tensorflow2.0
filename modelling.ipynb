{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(1, 3), dtype=int32, numpy=array([[1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones([1, 3], tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEmbeddings(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_buckets=None, embedding_size=None,*args, **kwargs):\n",
    "        super(GetEmbeddings, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding = tf.constant([[1.0,1.0,1.0,1.0],[2.0,2.0,2.0,2.0],[3.0,3.0,3.0,3.0],[4.0,4.0,4.0,4.0]]) # Embedding matrix\n",
    "    \n",
    "    def call(self, input):\n",
    "        user = input[0]\n",
    "        movie = input[1]\n",
    "        # Expand user to get it to a matrix of 1 and zeros instead\n",
    "        user = tf.expand_dims(user, 2)\n",
    "        user = tf.tile(user, [1,1, 4])\n",
    "        # check equality of array in t1 for each array in t2 element by element. This is possible because the equal function supports broadcasting. \n",
    "        equal =  tf.math.equal(tf.constant([1.0,1.0,1.0,1.0]), user)\n",
    "        # checking if all elements from  t1 match for all elements of some array in t2\n",
    "        equal_all = tf.reduce_all(equal, axis=2)\n",
    "        user_embeddings = self.embedding * user \n",
    "        # Get embeddings for the users based upon the movies he/she watched\n",
    "        # Expand the movie first\n",
    "        movies = tf.expand_dims(movie,2)\n",
    "        movies = tf.tile(movies, [1,1, 4])\n",
    "        # Get the embeddings\n",
    "        movie_embeddings = self.embedding * movies\n",
    "        # Only want the movies with values\n",
    "        equal_movie =  tf.math.not_equal(tf.constant([0.0,0.0,0.0,0.0]), movie_embeddings)\n",
    "        equal_all_movie = tf.reduce_all(equal, axis=1)\n",
    "        # Get the indicies where we have a movie\n",
    "        indices = tf.where(equal_movie)\n",
    "        # In order to to the pointwise multiplication I need to have the same shape so expand\n",
    "        out = tf.reshape(tf.gather_nd(movie_embeddings,indices),shape=(2,1,4))\n",
    "        out = tf.tile(out,multiples=[1,4,1])\n",
    "        # Point wise multiplication, each movie the user watched multiplied with this movie\n",
    "        output = tf.math.multiply(out,user_embeddings)\n",
    "        lenght =  tf.reduce_sum(tf.cast(equal_all, tf.float32),axis=1)\n",
    "        mean = tf.reduce_sum(tf.cast(output,dtype=tf.float32),axis=1) / tf.reshape(lenght, (-1, 1))\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEmbeddings(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_buckets=None, embedding_size=None,*args, **kwargs):\n",
    "        super(GetEmbeddings, self).__init__(*args, **kwargs)\n",
    "        self.movies = num_buckets\n",
    "        self.embedding_size = embedding_size\n",
    "        #self.shape = compute_output_shape\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "        self.embedding = tf.constant([[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]]) # Embedding matrix\n",
    "        self.kernel = self.add_variable(\"kernel\",\n",
    "                                    shape=[self.movies,\n",
    "                                           self.embedding_size],dtype=tf.float32,initializer=tf.keras.initializers.RandomUniform(),trainable=True)\n",
    "        \n",
    "    def call(self, input):\n",
    "        #input = tf.reshape(input)\n",
    "        #movies_new = concated[:,:4]\n",
    "        #users_new = concated[:,4:]\n",
    "        user = input[:,:self.movies]\n",
    "        movie = input[:,self.movies:]\n",
    "        # Expand user to get it to a matrix of 1 and zeros instead\n",
    "        user = tf.expand_dims(user, 2)\n",
    "        user = tf.tile(user, [1,1, self.embedding_size])\n",
    "        # check equality of array in t1 for each array in t2 element by element. This is possible because the equal function supports broadcasting. \n",
    "        #equal =  tf.math.equal(tf.constant([1,1,1,1]), user)       \n",
    "        equal =  tf.math.equal(tf.ones([1, self.embedding_size]), user)\n",
    "        # checking if all elements from  t1 match for all elements of some array in t2\n",
    "        equal_all = tf.reduce_all(equal, axis=2)      \n",
    "        #user_embeddings = self.embedding * user \n",
    "        user_embeddings = self.kernel * user\n",
    "        # Get embeddings for the users based upon the movies he/she watched\n",
    "        # Expand the movie first\n",
    "        movies = tf.expand_dims(movie,2)\n",
    "        movies = tf.tile(movies, [1,1, self.embedding_size])\n",
    "        # Get the embeddings\n",
    "        #movie_embeddings = self.embedding * movies      \n",
    "        movie_embeddings = self.kernel * movies        \n",
    "        # Only want the movies with values \n",
    "        equal_movie =  tf.math.not_equal(tf.zeros([1, self.embedding_size]), movie_embeddings)\n",
    "        #print(equal_movie)\n",
    "        equal_all_movie = tf.reduce_all(equal, axis=1)\n",
    "        #print(equal_all_movie)\n",
    "        # Get the indicies where we have a movie\n",
    "        indices = tf.where(equal_movie)\n",
    "        # In order to to the pointwise multiplication I need to have the same shape so expand\n",
    "        #print(tf.gather_nd(movie_embeddings,indices))\n",
    "        out = tf.reshape(tf.gather_nd(movie_embeddings,indices),shape=(tf.shape(user)[0],1,self.embedding_size))\n",
    "        out = tf.tile(out,multiples=[1,self.movies,1])\n",
    "        #print(tf.math.multiply(out[1],user_embeddings))\n",
    "        # Point wise multiplication, each movie the user watched multiplied with this movie\n",
    "        output = tf.math.multiply(user_embeddings,out)\n",
    "        #print(output)\n",
    "        #print(tf.shape(output))\n",
    "        #output = tf.reshape(output,shape=(self.batch_size,self.movies,self.embedding_size))\n",
    "        mean = tf.reduce_sum(tf.cast(output,dtype=tf.float32),axis=1) / self.movies\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10496, shape=(4, 10), dtype=float32, numpy=\n",
       "array([[-1.16437695e-05, -3.88579210e-05,  7.73757289e-04,\n",
       "        -2.47777323e-04,  1.94154534e-04,  6.78373792e-04,\n",
       "         2.05216475e-05,  7.09847081e-04,  6.54163159e-05,\n",
       "         8.94898585e-06],\n",
       "       [-2.02351166e-05,  2.57733132e-04, -3.31072835e-04,\n",
       "        -5.22725386e-05,  1.72020082e-04,  2.98175273e-05,\n",
       "         5.94616868e-05,  7.76321613e-05,  2.35067546e-05,\n",
       "         2.04360604e-05],\n",
       "       [ 2.27060518e-05, -3.96614138e-04,  2.16164044e-04,\n",
       "        -3.01132415e-04,  9.11516981e-05,  2.85599177e-04,\n",
       "        -2.70666569e-05,  1.97928952e-04, -5.09810598e-05,\n",
       "         8.35147785e-06],\n",
       "       [ 2.27060518e-05, -3.96614138e-04,  2.16164044e-04,\n",
       "        -3.01132415e-04,  9.11516981e-05,  2.85599177e-04,\n",
       "        -2.70666569e-05,  1.97928952e-04, -5.09810598e-05,\n",
       "         8.35147785e-06]], dtype=float32)>"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = GetEmbeddings(4,10)\n",
    "user = tf.constant([[1.0,1.0,1.0,1.0],[1.0,0.0,0.0,0.0],[1.0,0.0,0.0,0.0],[1.0,0.0,0.0,0.0]]) # Example user, two users\n",
    "#PROBLEMS PROBLEMS \n",
    "movie = tf.constant([[1.0,0.0,0.0,0.0],[0.0,1.0,0.0,0.0],[0.0,0.0,1.0,0.0],[0.0,0.0,1.0,0.0]]) \n",
    "concated = tf.concat([tf.cast(user,dtype=tf.int32),tf.cast(movie,tf.int32)],axis=1)\n",
    "concated = tf.cast(concated,tf.float32)\n",
    "layer(concated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10432, shape=(4, 8), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer with dense layer connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(8,)) # Don't forget the comma\n",
    "x  = GetEmbeddings(4,10)(inputs)\n",
    "x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "get_embeddings_173 (GetEmbed (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 425\n",
      "Trainable params: 425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              # List of metrics to monitor\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = concated\n",
    "y_train = tf.constant([0,0,0,0])\n",
    "x_val=x_train\n",
    "y_val=x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 4 samples\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6945 - binary_accuracy: 0.0000e+00 - val_loss: 0.6928 - val_binary_accuracy: 0.6562\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6921 - binary_accuracy: 1.0000 - val_loss: 0.6925 - val_binary_accuracy: 0.6562\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 779us/sample - loss: 0.6911 - binary_accuracy: 1.0000 - val_loss: 0.6921 - val_binary_accuracy: 0.6562\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6899 - binary_accuracy: 1.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.6562\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 923us/sample - loss: 0.6888 - binary_accuracy: 1.0000 - val_loss: 0.6915 - val_binary_accuracy: 0.6562\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6878 - binary_accuracy: 1.0000 - val_loss: 0.6912 - val_binary_accuracy: 0.6562\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6868 - binary_accuracy: 1.0000 - val_loss: 0.6909 - val_binary_accuracy: 0.6562\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.6859 - binary_accuracy: 1.0000 - val_loss: 0.6906 - val_binary_accuracy: 0.6562\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.6850 - binary_accuracy: 1.0000 - val_loss: 0.6903 - val_binary_accuracy: 0.6562\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6841 - binary_accuracy: 1.0000 - val_loss: 0.6901 - val_binary_accuracy: 0.6562\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 934us/sample - loss: 0.6832 - binary_accuracy: 1.0000 - val_loss: 0.6898 - val_binary_accuracy: 0.6562\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6824 - binary_accuracy: 1.0000 - val_loss: 0.6896 - val_binary_accuracy: 0.6562\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6815 - binary_accuracy: 1.0000 - val_loss: 0.6893 - val_binary_accuracy: 0.6562\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 831us/sample - loss: 0.6807 - binary_accuracy: 1.0000 - val_loss: 0.6891 - val_binary_accuracy: 0.6562\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 784us/sample - loss: 0.6799 - binary_accuracy: 1.0000 - val_loss: 0.6888 - val_binary_accuracy: 0.6562\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6791 - binary_accuracy: 1.0000 - val_loss: 0.6885 - val_binary_accuracy: 0.6562\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 846us/sample - loss: 0.6779 - binary_accuracy: 1.0000 - val_loss: 0.6881 - val_binary_accuracy: 0.6562\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 948us/sample - loss: 0.6768 - binary_accuracy: 1.0000 - val_loss: 0.6878 - val_binary_accuracy: 0.6562\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 729us/sample - loss: 0.6758 - binary_accuracy: 1.0000 - val_loss: 0.6875 - val_binary_accuracy: 0.6562\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6748 - binary_accuracy: 1.0000 - val_loss: 0.6872 - val_binary_accuracy: 0.6562\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6738 - binary_accuracy: 1.0000 - val_loss: 0.6869 - val_binary_accuracy: 0.6562\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 885us/sample - loss: 0.6728 - binary_accuracy: 1.0000 - val_loss: 0.6866 - val_binary_accuracy: 0.6562\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6718 - binary_accuracy: 1.0000 - val_loss: 0.6864 - val_binary_accuracy: 0.6562\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 813us/sample - loss: 0.6708 - binary_accuracy: 1.0000 - val_loss: 0.6861 - val_binary_accuracy: 0.6562\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 830us/sample - loss: 0.6699 - binary_accuracy: 1.0000 - val_loss: 0.6858 - val_binary_accuracy: 0.6562\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6689 - binary_accuracy: 1.0000 - val_loss: 0.6855 - val_binary_accuracy: 0.6562\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 737us/sample - loss: 0.6680 - binary_accuracy: 1.0000 - val_loss: 0.6852 - val_binary_accuracy: 0.6562\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 816us/sample - loss: 0.6670 - binary_accuracy: 1.0000 - val_loss: 0.6850 - val_binary_accuracy: 0.6562\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 755us/sample - loss: 0.6661 - binary_accuracy: 1.0000 - val_loss: 0.6847 - val_binary_accuracy: 0.6562\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 972us/sample - loss: 0.6651 - binary_accuracy: 1.0000 - val_loss: 0.6844 - val_binary_accuracy: 0.6562\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 858us/sample - loss: 0.6642 - binary_accuracy: 1.0000 - val_loss: 0.6841 - val_binary_accuracy: 0.6562\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 774us/sample - loss: 0.6632 - binary_accuracy: 1.0000 - val_loss: 0.6838 - val_binary_accuracy: 0.6562\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6623 - binary_accuracy: 1.0000 - val_loss: 0.6836 - val_binary_accuracy: 0.6562\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 808us/sample - loss: 0.6613 - binary_accuracy: 1.0000 - val_loss: 0.6833 - val_binary_accuracy: 0.6562\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 714us/sample - loss: 0.6603 - binary_accuracy: 1.0000 - val_loss: 0.6830 - val_binary_accuracy: 0.6562\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 676us/sample - loss: 0.6594 - binary_accuracy: 1.0000 - val_loss: 0.6828 - val_binary_accuracy: 0.6562\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 788us/sample - loss: 0.6584 - binary_accuracy: 1.0000 - val_loss: 0.6825 - val_binary_accuracy: 0.6562\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 773us/sample - loss: 0.6575 - binary_accuracy: 1.0000 - val_loss: 0.6822 - val_binary_accuracy: 0.6562\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 659us/sample - loss: 0.6565 - binary_accuracy: 1.0000 - val_loss: 0.6819 - val_binary_accuracy: 0.6562\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 693us/sample - loss: 0.6556 - binary_accuracy: 1.0000 - val_loss: 0.6817 - val_binary_accuracy: 0.6562\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 758us/sample - loss: 0.6546 - binary_accuracy: 1.0000 - val_loss: 0.6814 - val_binary_accuracy: 0.6562\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 713us/sample - loss: 0.6536 - binary_accuracy: 1.0000 - val_loss: 0.6811 - val_binary_accuracy: 0.6562\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 717us/sample - loss: 0.6527 - binary_accuracy: 1.0000 - val_loss: 0.6809 - val_binary_accuracy: 0.6562\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 669us/sample - loss: 0.6517 - binary_accuracy: 1.0000 - val_loss: 0.6806 - val_binary_accuracy: 0.6562\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 783us/sample - loss: 0.6507 - binary_accuracy: 1.0000 - val_loss: 0.6803 - val_binary_accuracy: 0.6562\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 771us/sample - loss: 0.6497 - binary_accuracy: 1.0000 - val_loss: 0.6801 - val_binary_accuracy: 0.6562\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 702us/sample - loss: 0.6488 - binary_accuracy: 1.0000 - val_loss: 0.6798 - val_binary_accuracy: 0.6562\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 603us/sample - loss: 0.6478 - binary_accuracy: 1.0000 - val_loss: 0.6795 - val_binary_accuracy: 0.6562\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 720us/sample - loss: 0.6468 - binary_accuracy: 1.0000 - val_loss: 0.6792 - val_binary_accuracy: 0.6562\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 822us/sample - loss: 0.6458 - binary_accuracy: 1.0000 - val_loss: 0.6790 - val_binary_accuracy: 0.6562\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=50,\n",
    "                    # We pass some validation for\n",
    "                    # monitoring validation loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
